{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RepO5dR0DP49"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split , cross_val_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report, precision_score,recall_score\n",
        "from scipy.fft import fft\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "from scipy.fft import fft\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader,random_split,TensorDataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/PRML LABs/PRML Major Project/audio_dataset.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "Uy-76jUXE0pZ",
        "outputId": "25a6f212-1ab8-4ee5-ef96-f9f635ca7f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Modality  Vocal channel  Emotion  Emotional intensity  Statement  \\\n",
              "0            3              1        5                    2          2   \n",
              "1            3              1        4                    2          2   \n",
              "2            3              1        1                    1          2   \n",
              "3            3              1        2                    2          2   \n",
              "4            3              1        4                    2          2   \n",
              "...        ...            ...      ...                  ...        ...   \n",
              "1435         3              1        8                    1          1   \n",
              "1436         3              1        5                    1          1   \n",
              "1437         3              1        2                    2          1   \n",
              "1438         3              1        4                    1          1   \n",
              "1439         3              1        6                    1          1   \n",
              "\n",
              "      Repetition  Actor             0             1             2  ...  \\\n",
              "0              1      1  2.329042e-04  1.441041e-03  3.753820e-04  ...   \n",
              "1              1      1  1.018356e-08 -1.005014e-08  9.524251e-09  ...   \n",
              "2              2      1  2.278331e-05  3.115162e-05  4.793048e-06  ...   \n",
              "3              1      1  2.429188e-05  2.923215e-05  8.048310e-06  ...   \n",
              "4              2      1  1.813627e-13 -1.941189e-13 -1.676032e-13  ...   \n",
              "...          ...    ...           ...           ...           ...  ...   \n",
              "1435           2     24  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
              "1436           2     24  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
              "1437           2     24  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
              "1438           2     24  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
              "1439           1     24 -1.072154e-10 -3.232369e-11  1.666647e-10  ...   \n",
              "\n",
              "             63935     63936     63937         63938         63939  \\\n",
              "0     4.532097e-02  0.050078  0.045070  3.029229e-02  3.539371e-02   \n",
              "1     3.179810e-05  0.000044  0.000026 -1.672583e-06  9.198144e-06   \n",
              "2     3.252479e-06  0.000013 -0.000002  3.341737e-07  5.308339e-07   \n",
              "3     8.280606e-03  0.008378  0.008179  7.974692e-03  7.836316e-03   \n",
              "4    -5.929249e-06  0.000005 -0.000005  9.120397e-06  2.205470e-05   \n",
              "...            ...       ...       ...           ...           ...   \n",
              "1435 -3.476922e-07 -0.000001  0.000004  3.806172e-05  3.835830e-07   \n",
              "1436 -2.550414e-06  0.000002 -0.000002  1.629342e-06 -1.235343e-06   \n",
              "1437  4.530484e-04  0.000148 -0.000035 -2.018864e-04 -2.044283e-04   \n",
              "1438  8.580230e-04  0.000592  0.000535  3.330597e-04  1.518707e-04   \n",
              "1439  3.091938e-02  0.030882  0.017899  2.623495e-02  1.683696e-02   \n",
              "\n",
              "             63940         63941         63942         63943         63944  \n",
              "0     5.646525e-02  5.664071e-02  5.869206e-02  5.510687e-02  6.350432e-02  \n",
              "1     2.301180e-05 -3.754093e-06  2.038091e-06 -1.250351e-06  7.715186e-07  \n",
              "2     1.392216e-05 -4.699850e-07 -2.686204e-08  2.657069e-07 -4.201772e-07  \n",
              "3     7.985077e-03  8.453447e-03  8.543141e-03  7.968901e-03  7.787952e-03  \n",
              "4     5.102658e-06  2.106591e-05  7.540939e-08  6.271493e-06  1.096370e-05  \n",
              "...            ...           ...           ...           ...           ...  \n",
              "1435  6.750817e-06  1.863219e-05  1.346969e-05  5.569830e-06 -3.534751e-06  \n",
              "1436  8.224735e-07 -5.586875e-07  2.645753e-06  5.533508e-05  4.465951e-05  \n",
              "1437 -1.777444e-04 -4.314623e-05  1.452080e-04  3.828391e-04  7.722454e-04  \n",
              "1438  1.039850e-04  7.744366e-05  1.735599e-05 -1.867246e-06 -5.283646e-06  \n",
              "1439 -9.608166e-04 -1.694898e-02 -3.794178e-02 -4.874028e-02 -5.946823e-02  \n",
              "\n",
              "[1440 rows x 63952 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3fab2da2-da22-4113-b6d5-7e9a4aa4f291\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modality</th>\n",
              "      <th>Vocal channel</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Emotional intensity</th>\n",
              "      <th>Statement</th>\n",
              "      <th>Repetition</th>\n",
              "      <th>Actor</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>...</th>\n",
              "      <th>63935</th>\n",
              "      <th>63936</th>\n",
              "      <th>63937</th>\n",
              "      <th>63938</th>\n",
              "      <th>63939</th>\n",
              "      <th>63940</th>\n",
              "      <th>63941</th>\n",
              "      <th>63942</th>\n",
              "      <th>63943</th>\n",
              "      <th>63944</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.329042e-04</td>\n",
              "      <td>1.441041e-03</td>\n",
              "      <td>3.753820e-04</td>\n",
              "      <td>...</td>\n",
              "      <td>4.532097e-02</td>\n",
              "      <td>0.050078</td>\n",
              "      <td>0.045070</td>\n",
              "      <td>3.029229e-02</td>\n",
              "      <td>3.539371e-02</td>\n",
              "      <td>5.646525e-02</td>\n",
              "      <td>5.664071e-02</td>\n",
              "      <td>5.869206e-02</td>\n",
              "      <td>5.510687e-02</td>\n",
              "      <td>6.350432e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.018356e-08</td>\n",
              "      <td>-1.005014e-08</td>\n",
              "      <td>9.524251e-09</td>\n",
              "      <td>...</td>\n",
              "      <td>3.179810e-05</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>-1.672583e-06</td>\n",
              "      <td>9.198144e-06</td>\n",
              "      <td>2.301180e-05</td>\n",
              "      <td>-3.754093e-06</td>\n",
              "      <td>2.038091e-06</td>\n",
              "      <td>-1.250351e-06</td>\n",
              "      <td>7.715186e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2.278331e-05</td>\n",
              "      <td>3.115162e-05</td>\n",
              "      <td>4.793048e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>3.252479e-06</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>-0.000002</td>\n",
              "      <td>3.341737e-07</td>\n",
              "      <td>5.308339e-07</td>\n",
              "      <td>1.392216e-05</td>\n",
              "      <td>-4.699850e-07</td>\n",
              "      <td>-2.686204e-08</td>\n",
              "      <td>2.657069e-07</td>\n",
              "      <td>-4.201772e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.429188e-05</td>\n",
              "      <td>2.923215e-05</td>\n",
              "      <td>8.048310e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>8.280606e-03</td>\n",
              "      <td>0.008378</td>\n",
              "      <td>0.008179</td>\n",
              "      <td>7.974692e-03</td>\n",
              "      <td>7.836316e-03</td>\n",
              "      <td>7.985077e-03</td>\n",
              "      <td>8.453447e-03</td>\n",
              "      <td>8.543141e-03</td>\n",
              "      <td>7.968901e-03</td>\n",
              "      <td>7.787952e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1.813627e-13</td>\n",
              "      <td>-1.941189e-13</td>\n",
              "      <td>-1.676032e-13</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.929249e-06</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>-0.000005</td>\n",
              "      <td>9.120397e-06</td>\n",
              "      <td>2.205470e-05</td>\n",
              "      <td>5.102658e-06</td>\n",
              "      <td>2.106591e-05</td>\n",
              "      <td>7.540939e-08</td>\n",
              "      <td>6.271493e-06</td>\n",
              "      <td>1.096370e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.476922e-07</td>\n",
              "      <td>-0.000001</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>3.806172e-05</td>\n",
              "      <td>3.835830e-07</td>\n",
              "      <td>6.750817e-06</td>\n",
              "      <td>1.863219e-05</td>\n",
              "      <td>1.346969e-05</td>\n",
              "      <td>5.569830e-06</td>\n",
              "      <td>-3.534751e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1436</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.550414e-06</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>-0.000002</td>\n",
              "      <td>1.629342e-06</td>\n",
              "      <td>-1.235343e-06</td>\n",
              "      <td>8.224735e-07</td>\n",
              "      <td>-5.586875e-07</td>\n",
              "      <td>2.645753e-06</td>\n",
              "      <td>5.533508e-05</td>\n",
              "      <td>4.465951e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1437</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>4.530484e-04</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>-0.000035</td>\n",
              "      <td>-2.018864e-04</td>\n",
              "      <td>-2.044283e-04</td>\n",
              "      <td>-1.777444e-04</td>\n",
              "      <td>-4.314623e-05</td>\n",
              "      <td>1.452080e-04</td>\n",
              "      <td>3.828391e-04</td>\n",
              "      <td>7.722454e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1438</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>8.580230e-04</td>\n",
              "      <td>0.000592</td>\n",
              "      <td>0.000535</td>\n",
              "      <td>3.330597e-04</td>\n",
              "      <td>1.518707e-04</td>\n",
              "      <td>1.039850e-04</td>\n",
              "      <td>7.744366e-05</td>\n",
              "      <td>1.735599e-05</td>\n",
              "      <td>-1.867246e-06</td>\n",
              "      <td>-5.283646e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1439</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>-1.072154e-10</td>\n",
              "      <td>-3.232369e-11</td>\n",
              "      <td>1.666647e-10</td>\n",
              "      <td>...</td>\n",
              "      <td>3.091938e-02</td>\n",
              "      <td>0.030882</td>\n",
              "      <td>0.017899</td>\n",
              "      <td>2.623495e-02</td>\n",
              "      <td>1.683696e-02</td>\n",
              "      <td>-9.608166e-04</td>\n",
              "      <td>-1.694898e-02</td>\n",
              "      <td>-3.794178e-02</td>\n",
              "      <td>-4.874028e-02</td>\n",
              "      <td>-5.946823e-02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1440 rows × 63952 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fab2da2-da22-4113-b6d5-7e9a4aa4f291')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3fab2da2-da22-4113-b6d5-7e9a4aa4f291 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3fab2da2-da22-4113-b6d5-7e9a4aa4f291');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ft = pd.read_csv('/content/drive/MyDrive/PRML LABs/PRML Major Project/audio_fft_dataset.csv')\n",
        "df_m  = pd.read_csv('/content/drive/MyDrive/PRML LABs/PRML Major Project/audio_mel_dataset.csv')\n",
        "df_ft \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "nf95mySOfh40",
        "outputId": "b0f10aa9-ca1e-4a5a-ab62-283cdc62a62f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  Modality  Vocal channel  Emotion  Emotional intensity  \\\n",
              "0              0         3              1        5                    2   \n",
              "1              1         3              1        4                    2   \n",
              "2              2         3              1        1                    1   \n",
              "3              3         3              1        2                    2   \n",
              "4              4         3              1        4                    2   \n",
              "...          ...       ...            ...      ...                  ...   \n",
              "1435        1435         3              1        8                    1   \n",
              "1436        1436         3              1        5                    1   \n",
              "1437        1437         3              1        2                    2   \n",
              "1438        1438         3              1        4                    1   \n",
              "1439        1439         3              1        6                    1   \n",
              "\n",
              "      Statement  Repetition  Actor         0         1  ...     63935  \\\n",
              "0             2           1      1  0.562838  0.524753  ...  0.356059   \n",
              "1             2           1      1  0.044707  0.018661  ...  0.007676   \n",
              "2             2           2      1  0.065975  0.058365  ...  0.032877   \n",
              "3             2           1      1  0.019496  0.071197  ...  0.030344   \n",
              "4             2           2      1  0.065471  0.036018  ...  0.012859   \n",
              "...         ...         ...    ...       ...       ...  ...       ...   \n",
              "1435          1           2     24  0.009685  0.021843  ...  0.006263   \n",
              "1436          1           2     24  0.001113  0.006725  ...  0.031690   \n",
              "1437          1           2     24  0.196957  0.110510  ...  0.058543   \n",
              "1438          1           2     24  0.080306  0.058616  ...  0.066964   \n",
              "1439          1           1     24  0.008611  0.007329  ...  0.025166   \n",
              "\n",
              "         63936     63937     63938     63939     63940     63941     63942  \\\n",
              "0     0.279785  0.296763  0.210512  0.331878  0.300090  0.318311  0.209626   \n",
              "1     0.006029  0.004431  0.020777  0.026970  0.018854  0.006725  0.011850   \n",
              "2     0.041382  0.016992  0.031579  0.035822  0.024165  0.023249  0.021512   \n",
              "3     0.067316  0.020739  0.035819  0.065218  0.026406  0.055942  0.050371   \n",
              "4     0.019099  0.006354  0.018731  0.023008  0.013048  0.019262  0.009203   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1435  0.009038  0.011431  0.007916  0.042234  0.043470  0.014524  0.016566   \n",
              "1436  0.049714  0.025524  0.032055  0.029004  0.035755  0.030565  0.017503   \n",
              "1437  0.031835  0.085497  0.108549  0.029150  0.055502  0.083451  0.081203   \n",
              "1438  0.085966  0.049558  0.047485  0.017968  0.039558  0.026743  0.008940   \n",
              "1439  0.007609  0.009041  0.029945  0.035148  0.010279  0.028460  0.029625   \n",
              "\n",
              "         63943     63944  \n",
              "0     0.407262  0.524753  \n",
              "1     0.015253  0.018661  \n",
              "2     0.024077  0.058365  \n",
              "3     0.066295  0.071197  \n",
              "4     0.044080  0.036018  \n",
              "...        ...       ...  \n",
              "1435  0.005730  0.021843  \n",
              "1436  0.013667  0.006725  \n",
              "1437  0.010991  0.110510  \n",
              "1438  0.017256  0.058616  \n",
              "1439  0.011848  0.007329  \n",
              "\n",
              "[1440 rows x 63953 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06cb5bf7-2f2d-41ea-8b6f-8915436640a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Modality</th>\n",
              "      <th>Vocal channel</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Emotional intensity</th>\n",
              "      <th>Statement</th>\n",
              "      <th>Repetition</th>\n",
              "      <th>Actor</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>...</th>\n",
              "      <th>63935</th>\n",
              "      <th>63936</th>\n",
              "      <th>63937</th>\n",
              "      <th>63938</th>\n",
              "      <th>63939</th>\n",
              "      <th>63940</th>\n",
              "      <th>63941</th>\n",
              "      <th>63942</th>\n",
              "      <th>63943</th>\n",
              "      <th>63944</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.562838</td>\n",
              "      <td>0.524753</td>\n",
              "      <td>...</td>\n",
              "      <td>0.356059</td>\n",
              "      <td>0.279785</td>\n",
              "      <td>0.296763</td>\n",
              "      <td>0.210512</td>\n",
              "      <td>0.331878</td>\n",
              "      <td>0.300090</td>\n",
              "      <td>0.318311</td>\n",
              "      <td>0.209626</td>\n",
              "      <td>0.407262</td>\n",
              "      <td>0.524753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.044707</td>\n",
              "      <td>0.018661</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007676</td>\n",
              "      <td>0.006029</td>\n",
              "      <td>0.004431</td>\n",
              "      <td>0.020777</td>\n",
              "      <td>0.026970</td>\n",
              "      <td>0.018854</td>\n",
              "      <td>0.006725</td>\n",
              "      <td>0.011850</td>\n",
              "      <td>0.015253</td>\n",
              "      <td>0.018661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.065975</td>\n",
              "      <td>0.058365</td>\n",
              "      <td>...</td>\n",
              "      <td>0.032877</td>\n",
              "      <td>0.041382</td>\n",
              "      <td>0.016992</td>\n",
              "      <td>0.031579</td>\n",
              "      <td>0.035822</td>\n",
              "      <td>0.024165</td>\n",
              "      <td>0.023249</td>\n",
              "      <td>0.021512</td>\n",
              "      <td>0.024077</td>\n",
              "      <td>0.058365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.019496</td>\n",
              "      <td>0.071197</td>\n",
              "      <td>...</td>\n",
              "      <td>0.030344</td>\n",
              "      <td>0.067316</td>\n",
              "      <td>0.020739</td>\n",
              "      <td>0.035819</td>\n",
              "      <td>0.065218</td>\n",
              "      <td>0.026406</td>\n",
              "      <td>0.055942</td>\n",
              "      <td>0.050371</td>\n",
              "      <td>0.066295</td>\n",
              "      <td>0.071197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.065471</td>\n",
              "      <td>0.036018</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012859</td>\n",
              "      <td>0.019099</td>\n",
              "      <td>0.006354</td>\n",
              "      <td>0.018731</td>\n",
              "      <td>0.023008</td>\n",
              "      <td>0.013048</td>\n",
              "      <td>0.019262</td>\n",
              "      <td>0.009203</td>\n",
              "      <td>0.044080</td>\n",
              "      <td>0.036018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>1435</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>0.009685</td>\n",
              "      <td>0.021843</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006263</td>\n",
              "      <td>0.009038</td>\n",
              "      <td>0.011431</td>\n",
              "      <td>0.007916</td>\n",
              "      <td>0.042234</td>\n",
              "      <td>0.043470</td>\n",
              "      <td>0.014524</td>\n",
              "      <td>0.016566</td>\n",
              "      <td>0.005730</td>\n",
              "      <td>0.021843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1436</th>\n",
              "      <td>1436</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>0.001113</td>\n",
              "      <td>0.006725</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031690</td>\n",
              "      <td>0.049714</td>\n",
              "      <td>0.025524</td>\n",
              "      <td>0.032055</td>\n",
              "      <td>0.029004</td>\n",
              "      <td>0.035755</td>\n",
              "      <td>0.030565</td>\n",
              "      <td>0.017503</td>\n",
              "      <td>0.013667</td>\n",
              "      <td>0.006725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1437</th>\n",
              "      <td>1437</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>0.196957</td>\n",
              "      <td>0.110510</td>\n",
              "      <td>...</td>\n",
              "      <td>0.058543</td>\n",
              "      <td>0.031835</td>\n",
              "      <td>0.085497</td>\n",
              "      <td>0.108549</td>\n",
              "      <td>0.029150</td>\n",
              "      <td>0.055502</td>\n",
              "      <td>0.083451</td>\n",
              "      <td>0.081203</td>\n",
              "      <td>0.010991</td>\n",
              "      <td>0.110510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1438</th>\n",
              "      <td>1438</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>0.080306</td>\n",
              "      <td>0.058616</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066964</td>\n",
              "      <td>0.085966</td>\n",
              "      <td>0.049558</td>\n",
              "      <td>0.047485</td>\n",
              "      <td>0.017968</td>\n",
              "      <td>0.039558</td>\n",
              "      <td>0.026743</td>\n",
              "      <td>0.008940</td>\n",
              "      <td>0.017256</td>\n",
              "      <td>0.058616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1439</th>\n",
              "      <td>1439</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>0.008611</td>\n",
              "      <td>0.007329</td>\n",
              "      <td>...</td>\n",
              "      <td>0.025166</td>\n",
              "      <td>0.007609</td>\n",
              "      <td>0.009041</td>\n",
              "      <td>0.029945</td>\n",
              "      <td>0.035148</td>\n",
              "      <td>0.010279</td>\n",
              "      <td>0.028460</td>\n",
              "      <td>0.029625</td>\n",
              "      <td>0.011848</td>\n",
              "      <td>0.007329</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1440 rows × 63953 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06cb5bf7-2f2d-41ea-8b6f-8915436640a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06cb5bf7-2f2d-41ea-8b6f-8915436640a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06cb5bf7-2f2d-41ea-8b6f-8915436640a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "YYnhBeT5gBfN",
        "outputId": "0fb838b3-05e0-49da-f4e7-e71ed6bff1bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Modality  Vocal channel  Emotion  Emotional intensity  Statement  \\\n",
              "0            3              1        5                    2          2   \n",
              "1            3              1        4                    2          2   \n",
              "2            3              1        1                    1          2   \n",
              "3            3              1        2                    2          2   \n",
              "4            3              1        4                    2          2   \n",
              "...        ...            ...      ...                  ...        ...   \n",
              "1435         3              1        8                    1          1   \n",
              "1436         3              1        5                    1          1   \n",
              "1437         3              1        2                    2          1   \n",
              "1438         3              1        4                    1          1   \n",
              "1439         3              1        6                    1          1   \n",
              "\n",
              "      Repetition  Actor             0             1             2  ...  \\\n",
              "0              1      1  7.569644e-07  5.010802e-06  8.384924e-06  ...   \n",
              "1              1      1  2.794822e-10  1.450041e-10  1.175133e-10  ...   \n",
              "2              2      1  1.332402e-07  1.478175e-07  1.084568e-07  ...   \n",
              "3              1      1  1.523058e-06  1.167175e-06  2.473346e-07  ...   \n",
              "4              2      1  1.922096e-10  3.086805e-10  1.442073e-10  ...   \n",
              "...          ...    ...           ...           ...           ...  ...   \n",
              "1435           2     24  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
              "1436           2     24  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
              "1437           2     24  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
              "1438           2     24  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
              "1439           1     24  5.361655e-11  6.365203e-11  3.540531e-12  ...   \n",
              "\n",
              "             15990         15991         15992         15993         15994  \\\n",
              "0     5.499699e-05  5.885491e-06  1.657120e-05  7.602131e-05  6.069553e-05   \n",
              "1     9.339636e-10  1.220944e-09  3.162984e-09  2.801177e-09  1.114704e-09   \n",
              "2     1.416472e-10  7.174033e-11  1.259040e-10  1.607572e-10  3.343664e-11   \n",
              "3     3.866556e-08  9.828029e-08  1.197246e-07  8.062022e-08  3.255798e-08   \n",
              "4     6.283513e-09  3.751002e-09  1.515500e-09  1.571249e-09  1.424604e-09   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "1435  9.985296e-10  4.968911e-10  3.221174e-10  3.396013e-10  3.091778e-10   \n",
              "1436  6.965746e-08  6.391710e-08  5.344007e-08  5.219970e-08  1.727351e-08   \n",
              "1437  2.448344e-08  8.441065e-09  8.191249e-08  2.261750e-07  1.162307e-07   \n",
              "1438  6.350594e-08  1.018883e-07  1.052788e-07  5.846529e-08  3.531843e-08   \n",
              "1439  5.118569e-06  4.369101e-06  1.032162e-06  9.775675e-08  6.991492e-08   \n",
              "\n",
              "             15995         15996         15997         15998         15999  \n",
              "0     2.774049e-05  1.739454e-05  3.164505e-05  3.757783e-05  7.998535e-05  \n",
              "1     4.183812e-10  3.350986e-10  3.824072e-10  3.206519e-10  2.361991e-10  \n",
              "2     5.016731e-11  4.086213e-11  3.167913e-11  1.258924e-10  2.130951e-10  \n",
              "3     2.372752e-09  6.229968e-09  3.475527e-08  3.888261e-08  5.073903e-07  \n",
              "4     1.195403e-09  5.786857e-10  5.123155e-10  4.680149e-10  3.469635e-10  \n",
              "...            ...           ...           ...           ...           ...  \n",
              "1435  3.297025e-10  4.210789e-10  4.688974e-10  7.026459e-10  5.663512e-10  \n",
              "1436  7.570125e-09  3.529409e-09  1.575603e-09  1.517090e-09  1.485708e-09  \n",
              "1437  5.961151e-08  5.394006e-08  5.558606e-08  3.873275e-08  4.627699e-08  \n",
              "1438  2.501399e-08  2.186149e-08  2.132620e-08  1.741378e-08  1.488148e-08  \n",
              "1439  6.688761e-08  2.848459e-07  1.374716e-06  1.566018e-06  3.060645e-05  \n",
              "\n",
              "[1440 rows x 16007 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f4fbde6-16b3-4eb7-920b-dc3ab1f97a7c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modality</th>\n",
              "      <th>Vocal channel</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Emotional intensity</th>\n",
              "      <th>Statement</th>\n",
              "      <th>Repetition</th>\n",
              "      <th>Actor</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>...</th>\n",
              "      <th>15990</th>\n",
              "      <th>15991</th>\n",
              "      <th>15992</th>\n",
              "      <th>15993</th>\n",
              "      <th>15994</th>\n",
              "      <th>15995</th>\n",
              "      <th>15996</th>\n",
              "      <th>15997</th>\n",
              "      <th>15998</th>\n",
              "      <th>15999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7.569644e-07</td>\n",
              "      <td>5.010802e-06</td>\n",
              "      <td>8.384924e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>5.499699e-05</td>\n",
              "      <td>5.885491e-06</td>\n",
              "      <td>1.657120e-05</td>\n",
              "      <td>7.602131e-05</td>\n",
              "      <td>6.069553e-05</td>\n",
              "      <td>2.774049e-05</td>\n",
              "      <td>1.739454e-05</td>\n",
              "      <td>3.164505e-05</td>\n",
              "      <td>3.757783e-05</td>\n",
              "      <td>7.998535e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.794822e-10</td>\n",
              "      <td>1.450041e-10</td>\n",
              "      <td>1.175133e-10</td>\n",
              "      <td>...</td>\n",
              "      <td>9.339636e-10</td>\n",
              "      <td>1.220944e-09</td>\n",
              "      <td>3.162984e-09</td>\n",
              "      <td>2.801177e-09</td>\n",
              "      <td>1.114704e-09</td>\n",
              "      <td>4.183812e-10</td>\n",
              "      <td>3.350986e-10</td>\n",
              "      <td>3.824072e-10</td>\n",
              "      <td>3.206519e-10</td>\n",
              "      <td>2.361991e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1.332402e-07</td>\n",
              "      <td>1.478175e-07</td>\n",
              "      <td>1.084568e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>1.416472e-10</td>\n",
              "      <td>7.174033e-11</td>\n",
              "      <td>1.259040e-10</td>\n",
              "      <td>1.607572e-10</td>\n",
              "      <td>3.343664e-11</td>\n",
              "      <td>5.016731e-11</td>\n",
              "      <td>4.086213e-11</td>\n",
              "      <td>3.167913e-11</td>\n",
              "      <td>1.258924e-10</td>\n",
              "      <td>2.130951e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.523058e-06</td>\n",
              "      <td>1.167175e-06</td>\n",
              "      <td>2.473346e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>3.866556e-08</td>\n",
              "      <td>9.828029e-08</td>\n",
              "      <td>1.197246e-07</td>\n",
              "      <td>8.062022e-08</td>\n",
              "      <td>3.255798e-08</td>\n",
              "      <td>2.372752e-09</td>\n",
              "      <td>6.229968e-09</td>\n",
              "      <td>3.475527e-08</td>\n",
              "      <td>3.888261e-08</td>\n",
              "      <td>5.073903e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1.922096e-10</td>\n",
              "      <td>3.086805e-10</td>\n",
              "      <td>1.442073e-10</td>\n",
              "      <td>...</td>\n",
              "      <td>6.283513e-09</td>\n",
              "      <td>3.751002e-09</td>\n",
              "      <td>1.515500e-09</td>\n",
              "      <td>1.571249e-09</td>\n",
              "      <td>1.424604e-09</td>\n",
              "      <td>1.195403e-09</td>\n",
              "      <td>5.786857e-10</td>\n",
              "      <td>5.123155e-10</td>\n",
              "      <td>4.680149e-10</td>\n",
              "      <td>3.469635e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>9.985296e-10</td>\n",
              "      <td>4.968911e-10</td>\n",
              "      <td>3.221174e-10</td>\n",
              "      <td>3.396013e-10</td>\n",
              "      <td>3.091778e-10</td>\n",
              "      <td>3.297025e-10</td>\n",
              "      <td>4.210789e-10</td>\n",
              "      <td>4.688974e-10</td>\n",
              "      <td>7.026459e-10</td>\n",
              "      <td>5.663512e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1436</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>6.965746e-08</td>\n",
              "      <td>6.391710e-08</td>\n",
              "      <td>5.344007e-08</td>\n",
              "      <td>5.219970e-08</td>\n",
              "      <td>1.727351e-08</td>\n",
              "      <td>7.570125e-09</td>\n",
              "      <td>3.529409e-09</td>\n",
              "      <td>1.575603e-09</td>\n",
              "      <td>1.517090e-09</td>\n",
              "      <td>1.485708e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1437</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>2.448344e-08</td>\n",
              "      <td>8.441065e-09</td>\n",
              "      <td>8.191249e-08</td>\n",
              "      <td>2.261750e-07</td>\n",
              "      <td>1.162307e-07</td>\n",
              "      <td>5.961151e-08</td>\n",
              "      <td>5.394006e-08</td>\n",
              "      <td>5.558606e-08</td>\n",
              "      <td>3.873275e-08</td>\n",
              "      <td>4.627699e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1438</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>6.350594e-08</td>\n",
              "      <td>1.018883e-07</td>\n",
              "      <td>1.052788e-07</td>\n",
              "      <td>5.846529e-08</td>\n",
              "      <td>3.531843e-08</td>\n",
              "      <td>2.501399e-08</td>\n",
              "      <td>2.186149e-08</td>\n",
              "      <td>2.132620e-08</td>\n",
              "      <td>1.741378e-08</td>\n",
              "      <td>1.488148e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1439</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>5.361655e-11</td>\n",
              "      <td>6.365203e-11</td>\n",
              "      <td>3.540531e-12</td>\n",
              "      <td>...</td>\n",
              "      <td>5.118569e-06</td>\n",
              "      <td>4.369101e-06</td>\n",
              "      <td>1.032162e-06</td>\n",
              "      <td>9.775675e-08</td>\n",
              "      <td>6.991492e-08</td>\n",
              "      <td>6.688761e-08</td>\n",
              "      <td>2.848459e-07</td>\n",
              "      <td>1.374716e-06</td>\n",
              "      <td>1.566018e-06</td>\n",
              "      <td>3.060645e-05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1440 rows × 16007 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f4fbde6-16b3-4eb7-920b-dc3ab1f97a7c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f4fbde6-16b3-4eb7-920b-dc3ab1f97a7c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f4fbde6-16b3-4eb7-920b-dc3ab1f97a7c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components = 500)\n",
        "lda = LDA(n_components = 7)"
      ],
      "metadata": {
        "id": "FC80-DgNHQJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.iloc[:,7:]\n",
        "y = df[\"Emotion\"]"
      ],
      "metadata": {
        "id": "fLaIkRoYHeio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = pca.fit(x)\n",
        "lda = lda.fit(x,y)\n",
        "X_pca = pca.transform(x)\n",
        "X_lda = lda.transform(x)"
      ],
      "metadata": {
        "id": "OIminQcqHcT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "xp_train, xp_test, yp_train, yp_test = train_test_split(X_pca,y,test_size=.20)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_lda,y,test_size=.20)"
      ],
      "metadata": {
        "id": "_UoM8GUXE0v3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title KNN\n",
        "knn1 = KNeighborsClassifier(n_neighbors=3)\n",
        "knn1.fit(x, y)\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n"
      ],
      "metadata": {
        "id": "g8rVvPMuKDTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fitting and Evaluating the Model\n",
        "knn = KNeighborsClassifier(n_neighbors=8)\n",
        "knn.fit(x_train,y_train)\n",
        "y_pred = knn.predict(x_test) \n",
        "\n",
        "acc = accuracy_score(y_test,y_pred)\n",
        "precision = precision_score(y_test,y_pred,average='micro')\n",
        "recall = recall_score(y_test,y_pred,average='micro')\n",
        "\n",
        "print(\"Accuracy : \",acc)\n",
        "print(\" Precision : \", precision )\n",
        "print(\" Recall : \", recall)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7xrOPi4KuCV",
        "outputId": "1a3f02ba-d593-4616-a5b7-f001093c065e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.9618055555555556\n",
            " Precision :  0.9618055555555556\n",
            " Recall :  0.9618055555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_values = [i for i in range(1,31)]\n",
        "scores = []\n",
        "x = scaler.fit_transform(X_lda)\n",
        "\n",
        "for k in k_values:\n",
        "  knn = KNeighborsClassifier(n_neighbors= k)\n",
        "  score = cross_val_score(knn,x,y,cv = 5)\n",
        "  scores.append(np.mean(score))\n",
        "print(scores)\n"
      ],
      "metadata": {
        "id": "boDOia0DYcPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c7bf80e-4cb9-49cb-f818-21611fb38950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9701388888888889, 0.9673611111111111, 0.9666666666666666, 0.9666666666666668, 0.9652777777777779, 0.9659722222222221, 0.9659722222222221, 0.9659722222222221, 0.9645833333333333, 0.9638888888888889, 0.9638888888888889, 0.9638888888888889, 0.9638888888888889, 0.9631944444444445, 0.9645833333333333, 0.9638888888888889, 0.9631944444444445, 0.9638888888888889, 0.9652777777777779, 0.9645833333333333, 0.9625, 0.9618055555555556, 0.9625, 0.9631944444444445, 0.9631944444444445, 0.9631944444444445, 0.9625, 0.9631944444444445, 0.9631944444444445, 0.9631944444444445]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "best_index = np.argmax(scores)\n",
        "best_k     = k_values[best_index]\n",
        "\n",
        "knn_k = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn_k.fit(x_train,y_train)\n",
        "y_pred_ = knn_k.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test,y_pred_)\n",
        "precision = precision_score(y_test,y_pred_,average='micro')\n",
        "recall = recall_score(y_test,y_pred_,average='micro')\n",
        "\n",
        "print(\"accuracy : \", accuracy )\n",
        "print(\" Precision : \", precision )\n",
        "print(\" Recall : \", recall)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YHhJE8eV116",
        "outputId": "b11f7387-eb14-41f7-86eb-9c555370b9a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy :  0.9756944444444444\n",
            " Precision :  0.9756944444444444\n",
            " Recall :  0.9756944444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AKBmKTIeYg8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "na3b7TkAYjDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SVM\n",
        "\n",
        "clf = SVC(kernel = \"linear\")\n",
        "clf_rbf = SVC(kernel = \"rbf\")\n",
        "\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred = clf.predict(x_test)\n",
        "acc_svm = accuracy_score(y_test,y_pred)\n",
        "precision_svm = precision_score(y_test,y_pred,average='micro')\n",
        "recall_svm = recall_score(y_test,y_pred,average='micro')\n",
        "\n",
        "clf_rbf.fit(x_train,y_train)\n",
        "y_pred_rbf = clf_rbf.predict(x_test)\n",
        "acc_svm_rbf= accuracy_score(y_test,y_pred_rbf)\n",
        "precision_svm_rbf = precision_score(y_test,y_pred_rbf,average='micro')\n",
        "recall_svm_rbf = recall_score(y_test,y_pred_rbf,average='micro')\n",
        "\n",
        "print(\"Accuracy : \",acc_svm)\n",
        "print(\" Precision   : \", precision_svm )\n",
        "print(\" Recall  : \", recall_svm)\n",
        "\n",
        "print(\"Accuracy rbf : \",acc_svm_rbf)\n",
        "print(\" Precision rbf : \", precision_svm_rbf )\n",
        "print(\" Recall rbf : \", recall_svm_rbf)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en4J2KAEYi_E",
        "outputId": "9efee804-ee89-429f-89a6-1494e33a3b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.9618055555555556\n",
            " Precision   :  0.9618055555555556\n",
            " Recall  :  0.9618055555555556\n",
            "Accuracy rbf :  0.9652777777777778\n",
            " Precision rbf :  0.9652777777777778\n",
            " Recall rbf :  0.9652777777777778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model KNN , SVM with kernel -- linear and rbf on Fourier Transform Dataset"
      ],
      "metadata": {
        "id": "dJu-aQzes6ba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title FFT\n",
        "\n",
        "x1 = df_ft.iloc[:,7:]\n",
        "y1 = df_ft[\"Emotion\"]\n",
        "lda = lda.fit(x1,y1)\n",
        "# X1_pca = pca.transform(x1)\n",
        "X1_lda = lda.transform(x1)\n",
        "x_train1, x_test1, y_train1, y_test1 = train_test_split(X1_lda,y1,test_size=.20)\n",
        "\n",
        "knn1 = KNeighborsClassifier(n_neighbors=3)\n",
        "knn1.fit(x1, y1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train1 = scaler.fit_transform(x_train1)\n",
        "x_test1 = scaler.transform(x_test1)\n",
        "\n",
        "#@title Fitting and Evaluating the Model\n",
        "knn = KNeighborsClassifier(n_neighbors=8)\n",
        "knn.fit(x_train1,y_train1)\n",
        "y_pred_ = knn.predict(x_test1)\n",
        "acc = accuracy_score(y_test1,y_pred_)\n",
        "precision = precision_score(y_test1,y_pred_,average='micro')\n",
        "recall = recall_score(y_test1,y_pred_,average='micro')\n",
        "\n",
        "print(\"Accuracy : \",acc)\n",
        "print(\" Precision : \", precision )\n",
        "print(\" Recall : \", recall)\n",
        "\n",
        "k_values = [i for i in range(1,31)]\n",
        "scores = []\n",
        "x = scaler.fit_transform(x)\n",
        "\n",
        "for k in k_values:\n",
        "  knn = KNeighborsClassifier(n_neighbors= k)\n",
        "  score = cross_val_score(knn,x,y,cv = 5)\n",
        "  scores.append(np.mean(score))\n",
        "print(scores)\n",
        "# sns.lineplot(x = k_values, y = scores,maker= '*')\n",
        "# plt.xlabel(\"K Values\")\n",
        "# plt.ylabel(\"Accuracy Score\")\n",
        "\n",
        "\n",
        "best_index = np.argmax(scores)\n",
        "best_k     = k_values[best_index]\n",
        "\n",
        "knn_k = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn_k.fit(x_train1,y_train1)\n",
        "y_pred__ = knn_k.predict(x_test1)\n",
        "\n",
        "accuracy = accuracy_score(y_test1,y_pred__)\n",
        "precision = precision_score(y_test1,y_pred__,average='micro')\n",
        "recall = recall_score(y_test1,y_pred__,average='micro')\n",
        "\n",
        "print(\"accuracy : \", accuracy )\n",
        "print(\" Precision : \", precision )\n",
        "print(\" Recall : \", recall)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "#@title SVM\n",
        "\n",
        "clf1 = SVC(kernel = \"linear\")\n",
        "clf1_rbf = SVC(kernel = \"rbf\")\n",
        "\n",
        "clf1.fit(x_train1,y_train1)\n",
        "y_pred = clf1.predict(x_test1)\n",
        "acc_svm1 = accuracy_score(y_test1,y_pred)\n",
        "precision_svm1 = precision_score(y_test1,y_pred,average='micro')\n",
        "recall_svm1 = recall_score(y_test1,y_pred,average='micro')\n",
        "\n",
        "clf1_rbf.fit(x_train1,y_train1)\n",
        "y_pred_rbf = clf1_rbf.predict(x_test1)\n",
        "acc_svm1_rbf= accuracy_score(y_test1,y_pred_rbf)\n",
        "precision_svm1_rbf = precision_score(y_test1,y_pred_rbf,average='micro')\n",
        "recall_svm1_rbf = recall_score(y_test1,y_pred_rbf,average='micro')\n",
        "\n",
        "print(\"Accuracy : \",acc_svm1)\n",
        "print(\" Precision   : \", precision_svm1 )\n",
        "print(\" Recall  : \", recall_svm1)\n",
        "\n",
        "print(\"Accuracy rbf : \",acc_svm1_rbf)\n",
        "print(\" Precision rbf : \", precision_svm1_rbf )\n",
        "print(\" Recall rbf : \", recall_svm1_rbf)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4rHVWalhwvB",
        "outputId": "7882da3b-3c76-4c2a-e046-2038c8335228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.96875\n",
            " Precision :  0.96875\n",
            " Recall :  0.96875\n",
            "[0.9701388888888889, 0.9673611111111111, 0.9666666666666666, 0.9666666666666668, 0.9652777777777779, 0.9659722222222221, 0.9659722222222221, 0.9659722222222221, 0.9645833333333333, 0.9638888888888889, 0.9638888888888889, 0.9638888888888889, 0.9638888888888889, 0.9631944444444445, 0.9645833333333333, 0.9638888888888889, 0.9631944444444445, 0.9638888888888889, 0.9652777777777779, 0.9645833333333333, 0.9625, 0.9618055555555556, 0.9625, 0.9631944444444445, 0.9631944444444445, 0.9631944444444445, 0.9625, 0.9631944444444445, 0.9631944444444445, 0.9631944444444445]\n",
            "accuracy :  0.9583333333333334\n",
            " Precision :  0.9583333333333334\n",
            " Recall :  0.9583333333333334\n",
            "Accuracy :  0.9548611111111112\n",
            " Precision   :  0.9548611111111112\n",
            " Recall  :  0.9548611111111112\n",
            "Accuracy rbf :  0.9722222222222222\n",
            " Precision rbf :  0.9722222222222222\n",
            " Recall rbf :  0.9722222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BvvQEJGotmTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model  KNN, SVM kernel -- linear , rbf on mel. dataset"
      ],
      "metadata": {
        "id": "tJPe5W7-txD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title mel\n",
        "\n",
        "\n",
        "x2 = df.iloc[:,7:]\n",
        "y2 = df[\"Emotion\"]\n",
        "lda = lda.fit(x2,y2)\n",
        "\n",
        "X2_lda = lda.transform(x2)\n",
        "x_train2, x_test2, y_train2, y_test2 = train_test_split(X2_lda,y2,test_size=.20)\n",
        "\n",
        "knn1 = KNeighborsClassifier(n_neighbors=3)\n",
        "knn1.fit(x2, y2)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train2 = scaler.fit_transform(x_train2)\n",
        "x_test2 = scaler.transform(x_test2)\n",
        "\n",
        "#@title Fitting and Evaluating the Model\n",
        "knn = KNeighborsClassifier(n_neighbors=8)\n",
        "knn.fit(x_train2,y_train2)\n",
        "y_pred = knn.predict(x_test2)\n",
        "acc = accuracy_score(y_test2,y_pred)\n",
        "precision = precision_score(y_test2,y_pred,average='micro')\n",
        "recall = recall_score(y_test2,y_pred,average='micro')\n",
        "\n",
        "print(\"Accuracy : \",acc)\n",
        "print(\" Precision : \", precision )\n",
        "print(\" Recall : \", recall)\n",
        "\n",
        "k_values = [i for i in range(1,31)]\n",
        "scores = []\n",
        "x = scaler.fit_transform(x)\n",
        "\n",
        "for k in k_values:\n",
        "  knn = KNeighborsClassifier(n_neighbors= k)\n",
        "  score = cross_val_score(knn,x,y,cv = 5)\n",
        "  scores.append(np.mean(score))\n",
        "print(scores)\n",
        "\n",
        "\n",
        "\n",
        "best_index = np.argmax(scores)\n",
        "best_k     = k_values[best_index]\n",
        "\n",
        "knn_k = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn_k.fit(x_train2,y_train2)\n",
        "y_pred_ = knn_k.predict(x_test2)\n",
        "\n",
        "accuracy = accuracy_score(y_test2,y_pred_)\n",
        "precision = precision_score(y_test2,y_pred_,average='micro')\n",
        "recall = recall_score(y_test2,y_pred_,average='micro')\n",
        "\n",
        "print(\"accuracy : \", accuracy )\n",
        "print(\" Precision : \", precision )\n",
        "print(\" Recall : \", recall)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "#@title SVM\n",
        "\n",
        "clf = SVC(kernel = \"linear\")\n",
        "clf_rbf = SVC(kernel = \"rbf\")\n",
        "\n",
        "clf.fit(x_train2,y_train2)\n",
        "y_pred = clf.predict(x_test2)\n",
        "acc_svm = accuracy_score(y_test2,y_pred)\n",
        "precision_svm = precision_score(y_test2,y_pred,average='micro')\n",
        "recall_svm = recall_score(y_test2,y_pred,average='micro')\n",
        "\n",
        "clf_rbf.fit(x_train2,y_train2)\n",
        "y_pred_rbf = clf_rbf.predict(x_test2)\n",
        "acc_svm_rbf= accuracy_score(y_test2,y_pred_rbf)\n",
        "precision_svm_rbf = precision_score(y_test2,y_pred_rbf,average='micro')\n",
        "recall_svm_rbf = recall_score(y_test2,y_pred_rbf,average='micro')\n",
        "\n",
        "print(\"Accuracy : \",acc_svm)\n",
        "print(\" Precision   : \", precision_svm )\n",
        "print(\" Recall  : \", recall_svm)\n",
        "\n",
        "print(\"Accuracy rbf : \",acc_svm_rbf)\n",
        "print(\" Precision rbf : \", precision_svm_rbf )\n",
        "print(\" Recall rbf : \", recall_svm_rbf)\n",
        "\n"
      ],
      "metadata": {
        "id": "kYPTpFATh18O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d55ed1c-d9d1-44d6-d83e-d7e9e8555cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.9652777777777778\n",
            " Precision :  0.9652777777777778\n",
            " Recall :  0.9652777777777778\n",
            "[0.9701388888888889, 0.9673611111111111, 0.9666666666666666, 0.9666666666666668, 0.9652777777777779, 0.9659722222222221, 0.9659722222222221, 0.9659722222222221, 0.9645833333333333, 0.9638888888888889, 0.9638888888888889, 0.9638888888888889, 0.9638888888888889, 0.9631944444444445, 0.9645833333333333, 0.9638888888888889, 0.9631944444444445, 0.9638888888888889, 0.9652777777777779, 0.9645833333333333, 0.9625, 0.9618055555555556, 0.9625, 0.9631944444444445, 0.9631944444444445, 0.9631944444444445, 0.9625, 0.9631944444444445, 0.9631944444444445, 0.9631944444444445]\n",
            "accuracy :  0.9722222222222222\n",
            " Precision :  0.9722222222222222\n",
            " Recall :  0.9722222222222222\n",
            "Accuracy :  0.9583333333333334\n",
            " Precision   :  0.9583333333333334\n",
            " Recall  :  0.9583333333333334\n",
            "Accuracy rbf :  0.9583333333333334\n",
            " Precision rbf :  0.9583333333333334\n",
            " Recall rbf :  0.9583333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/PRML LABs/PRML Major Project/audio_fft_dataset.csv\")"
      ],
      "metadata": {
        "id": "FjSjOH70QWxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components = 500)\n",
        "lda = LDA(n_components = 7)\n",
        "Y = dataset[\"Emotion\"]\n",
        "X = dataset.iloc[:,7:]"
      ],
      "metadata": {
        "id": "XnjW3qkFQngX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = pca.fit(X)\n",
        "lda = lda.fit(X,Y)\n",
        "X_pca = pca.transform(X)\n",
        "X_lda = lda.transform(X)\n",
        "X_pca = torch.tensor(X_pca)\n",
        "X_lda = torch.tensor(X_lda)\n",
        "Y = torch.tensor(Y.values - 1)"
      ],
      "metadata": {
        "id": "hjsYSLDWQtFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_pca = TensorDataset(X_pca,Y)\n",
        "dataset_lda = TensorDataset(X_lda,Y)\n",
        "train_pca,test_pca,valid_pca = random_split(dataset_pca,[864,288,288])\n",
        "train_lda,test_lda,valid_lda = random_split(dataset_lda,[864,288,288])\n",
        "\n"
      ],
      "metadata": {
        "id": "bRRdQX-dQ6F9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pca_dl = DataLoader(dataset = train_pca,batch_size = 64)\n",
        "test_pca_dl = DataLoader(dataset = test_pca)\n",
        "valid_pca_dl = DataLoader(dataset = valid_pca)\n",
        "train_lda_dl = DataLoader(dataset = train_lda,batch_size = 64)\n",
        "test_lda_dl = DataLoader(dataset = test_lda)\n",
        "valid_lda_dl = DataLoader(dataset = valid_lda)"
      ],
      "metadata": {
        "id": "om7RFqrkRDFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class model_pca_relu(nn.Module):\n",
        "  def __init__(self,input_size,num_classes):\n",
        "    super(model_pca_relu,self).__init__()\n",
        "    self.hid_lay1 = nn.Linear(input_size,500)\n",
        "    self.act_fn1 = nn.ReLU()\n",
        "    self.hid_lay2 = nn.Linear(500,300)\n",
        "    self.act_fn2 = nn.ReLU()\n",
        "    self.hid_lay3 = nn.Linear(300,8)\n",
        "    self.act_fn3 = nn.ReLU()\n",
        "    self.output_layer = nn.Softmax()\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = self.hid_lay1(x)\n",
        "    x = self.act_fn1(x)\n",
        "    x = self.hid_lay2(x)\n",
        "    x = self.act_fn2(x)\n",
        "    x = self.hid_lay3(x)\n",
        "    x = self.act_fn3(x)\n",
        "    x = self.output_layer(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n",
        "    "
      ],
      "metadata": {
        "id": "HJNJdcv0RZFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f3efd5-bbdf-475c-f6ca-fd1add77a69d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_pca_relu(500,8).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(model.parameters(),lr = 0.0001)\n",
        "best_acc = 0.0"
      ],
      "metadata": {
        "id": "0z4Ucys9RyHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(1000):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    acc = 0.0\n",
        "    j = 0\n",
        "    for i, data in enumerate(train_pca):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device = device).float()\n",
        "        labels = labels.to(device = device)\n",
        "        opt.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        running_loss += loss.item()\n",
        "        _,pred = torch.max(outputs,0)\n",
        "        pred = pred.cpu().numpy()\n",
        "        labels = labels.cpu().numpy()\n",
        "        acc += np.sum(pred == labels)\n",
        "        j += 1\n",
        "    if epoch % 25 == 24:\n",
        "        print(f'[{epoch + 1}] Training : loss: {running_loss:0.2f} accuracy : {acc/j}',end='')\n",
        "    with torch.no_grad():\n",
        "      acc = 0.0\n",
        "      j = 0\n",
        "      running_loss = 0.0\n",
        "      for i, data in enumerate(valid_pca):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device = device).float()\n",
        "        labels = labels.to(device = device)\n",
        "        opt.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "        _,pred = torch.max(outputs,0)\n",
        "        pred = pred.cpu().numpy()\n",
        "        labels = labels.cpu().numpy()\n",
        "        acc += np.sum(pred == labels)\n",
        "        j += 1\n",
        "      if best_acc < acc/j:\n",
        "        torch.save(model,'/content/drive/MyDrive/PRML LABs/PRML Major Project/model_pca.pth')\n",
        "        best_acc = acc/j\n",
        "    if epoch % 25 == 24:\n",
        "        print(f' Validation :  loss: {running_loss:0.2f} accuracy : {acc/j}')\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "Yvp9X8xFSHkE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eba30861-ed18-4c8e-eea5-6ab7aacb2b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-03d8390d25d3>:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = self.output_layer(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25] Training : loss: 1490.77 accuracy : 0.5462962962962963 Validation :  loss: 575.33 accuracy : 0.2673611111111111\n",
            "[50] Training : loss: 1360.82 accuracy : 0.6967592592592593 Validation :  loss: 555.87 accuracy : 0.3333333333333333\n",
            "[75] Training : loss: 1290.73 accuracy : 0.78125 Validation :  loss: 558.43 accuracy : 0.3194444444444444\n",
            "[100] Training : loss: 1275.06 accuracy : 0.7974537037037037 Validation :  loss: 546.41 accuracy : 0.3715277777777778\n",
            "[125] Training : loss: 1258.06 accuracy : 0.8159722222222222 Validation :  loss: 563.28 accuracy : 0.3194444444444444\n",
            "[150] Training : loss: 1249.17 accuracy : 0.8287037037037037 Validation :  loss: 556.65 accuracy : 0.3298611111111111\n",
            "[175] Training : loss: 1244.71 accuracy : 0.8344907407407407 Validation :  loss: 557.16 accuracy : 0.3402777777777778\n",
            "[200] Training : loss: 1245.26 accuracy : 0.8310185185185185 Validation :  loss: 554.21 accuracy : 0.3506944444444444\n",
            "[225] Training : loss: 1237.90 accuracy : 0.8414351851851852 Validation :  loss: 550.76 accuracy : 0.3576388888888889\n",
            "[250] Training : loss: 1230.85 accuracy : 0.8495370370370371 Validation :  loss: 541.47 accuracy : 0.3888888888888889\n",
            "[275] Training : loss: 1237.75 accuracy : 0.8402777777777778 Validation :  loss: 556.35 accuracy : 0.3402777777777778\n",
            "[300] Training : loss: 1227.71 accuracy : 0.8530092592592593 Validation :  loss: 550.04 accuracy : 0.3645833333333333\n",
            "[325] Training : loss: 1224.68 accuracy : 0.8564814814814815 Validation :  loss: 554.81 accuracy : 0.34375\n",
            "[350] Training : loss: 1227.51 accuracy : 0.8530092592592593 Validation :  loss: 544.48 accuracy : 0.3784722222222222\n",
            "[375] Training : loss: 1219.74 accuracy : 0.8622685185185185 Validation :  loss: 542.16 accuracy : 0.3888888888888889\n",
            "[400] Training : loss: 1219.74 accuracy : 0.8622685185185185 Validation :  loss: 553.98 accuracy : 0.3472222222222222\n",
            "[425] Training : loss: 1220.27 accuracy : 0.8622685185185185 Validation :  loss: 553.83 accuracy : 0.3472222222222222\n",
            "[450] Training : loss: 1216.74 accuracy : 0.8657407407407407 Validation :  loss: 563.54 accuracy : 0.3194444444444444\n",
            "[475] Training : loss: 1242.31 accuracy : 0.8368055555555556 Validation :  loss: 561.48 accuracy : 0.3229166666666667\n",
            "[500] Training : loss: 1216.74 accuracy : 0.8657407407407407 Validation :  loss: 556.72 accuracy : 0.34375\n",
            "[525] Training : loss: 1223.69 accuracy : 0.8576388888888888 Validation :  loss: 552.44 accuracy : 0.3576388888888889\n",
            "[550] Training : loss: 1216.74 accuracy : 0.8657407407407407 Validation :  loss: 554.41 accuracy : 0.3472222222222222\n",
            "[575] Training : loss: 1225.74 accuracy : 0.8553240740740741 Validation :  loss: 556.60 accuracy : 0.34375\n",
            "[600] Training : loss: 1217.04 accuracy : 0.8657407407407407 Validation :  loss: 553.17 accuracy : 0.3506944444444444\n",
            "[625] Training : loss: 1225.25 accuracy : 0.8553240740740741 Validation :  loss: 551.98 accuracy : 0.3576388888888889\n",
            "[650] Training : loss: 1216.74 accuracy : 0.8657407407407407 Validation :  loss: 555.82 accuracy : 0.34375\n",
            "[675] Training : loss: 1216.74 accuracy : 0.8657407407407407 Validation :  loss: 555.59 accuracy : 0.34375\n",
            "[700] Training : loss: 1217.81 accuracy : 0.8645833333333334 Validation :  loss: 552.21 accuracy : 0.3541666666666667\n",
            "[725] Training : loss: 1213.74 accuracy : 0.8692129629629629 Validation :  loss: 558.85 accuracy : 0.3333333333333333\n",
            "[750] Training : loss: 1213.74 accuracy : 0.8692129629629629 Validation :  loss: 553.26 accuracy : 0.3541666666666667\n",
            "[775] Training : loss: 1224.04 accuracy : 0.8576388888888888 Validation :  loss: 563.17 accuracy : 0.3159722222222222\n",
            "[800] Training : loss: 1213.74 accuracy : 0.8692129629629629 Validation :  loss: 560.55 accuracy : 0.3263888888888889\n",
            "[825] Training : loss: 1221.47 accuracy : 0.8599537037037037 Validation :  loss: 555.02 accuracy : 0.3472222222222222\n",
            "[850] Training : loss: 1213.74 accuracy : 0.8692129629629629 Validation :  loss: 559.73 accuracy : 0.3298611111111111\n",
            "[875] Training : loss: 1212.74 accuracy : 0.8703703703703703 Validation :  loss: 561.98 accuracy : 0.3229166666666667\n",
            "[900] Training : loss: 1212.74 accuracy : 0.8703703703703703 Validation :  loss: 562.18 accuracy : 0.3194444444444444\n",
            "[925] Training : loss: 1214.74 accuracy : 0.8680555555555556 Validation :  loss: 552.59 accuracy : 0.3576388888888889\n",
            "[950] Training : loss: 1214.74 accuracy : 0.8680555555555556 Validation :  loss: 552.80 accuracy : 0.3506944444444444\n",
            "[975] Training : loss: 1214.74 accuracy : 0.8680555555555556 Validation :  loss: 553.43 accuracy : 0.3506944444444444\n",
            "[1000] Training : loss: 1213.74 accuracy : 0.8692129629629629 Validation :  loss: 545.95 accuracy : 0.3784722222222222\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model =torch.load('/content/drive/MyDrive/PRML LABs/PRML Major Project/model_pca.pth')\n",
        "with torch.no_grad():\n",
        "    acc = 0.0\n",
        "    j = 0\n",
        "    for i, data in enumerate(test_pca):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device = device).float()\n",
        "        opt.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        _,pred = torch.max(outputs,0)\n",
        "        pred = pred.cpu().numpy()\n",
        "        labels = labels.numpy()\n",
        "        acc += np.sum(pred == labels)\n",
        "        j += 1\n",
        "print(f\"accuracy : {acc/j}\")"
      ],
      "metadata": {
        "id": "DFpAp_eGSNj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97fb15cd-1680-46af-cf70-4581c9070cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.3854166666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-03d8390d25d3>:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = self.output_layer(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_pca_relu(7,8).to(device)\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(model.parameters(),lr = 0.0001)\n",
        "\n",
        "best_acc = 0.0\n",
        "for epoch in range(600):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    acc = 0.0\n",
        "    j = 0\n",
        "    for i, data in enumerate(train_lda):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device = device).float()\n",
        "        labels = labels.to(device = device)\n",
        "        opt.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        running_loss += loss.item()\n",
        "        _,pred = torch.max(outputs,0)\n",
        "        pred = pred.cpu().numpy()\n",
        "        labels = labels.cpu().numpy()\n",
        "        acc += np.sum(pred == labels)\n",
        "        j += 1\n",
        "    if epoch % 25 == 24:\n",
        "        print(f'[{epoch + 1}] Training : loss: {running_loss:0.2f} accuracy : {acc/j}',end='')\n",
        "    with torch.no_grad():\n",
        "      acc = 0.0\n",
        "      j = 0\n",
        "      running_loss = 0.0\n",
        "      for i, data in enumerate(valid_lda):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device = device).float()\n",
        "        labels = labels.to(device = device)\n",
        "        opt.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "        _,pred = torch.max(outputs,0)\n",
        "        pred = pred.cpu().numpy()\n",
        "        labels = labels.cpu().numpy()\n",
        "        acc += np.sum(pred == labels)\n",
        "        j += 1\n",
        "      if best_acc < acc/j:\n",
        "        torch.save(model,'/content/drive/MyDrive/PRML LABs/PRML Major Project/model_lda.pth')\n",
        "        best_acc = acc/j\n",
        "    if epoch % 25 == 24:\n",
        "        print(f' Validation :  loss: {running_loss:0.2f} accuracy : {acc/j}')\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "3aObPl9ESRvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93381d7c-fb63-4c9d-8056-19a47ee22e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-03d8390d25d3>:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = self.output_layer(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25] Training : loss: 1389.48 accuracy : 0.59375 Validation :  loss: 471.66 accuracy : 0.5625\n",
            "[50] Training : loss: 1388.75 accuracy : 0.59375 Validation :  loss: 470.92 accuracy : 0.5625\n",
            "[75] Training : loss: 1388.48 accuracy : 0.59375 Validation :  loss: 471.34 accuracy : 0.5625\n",
            "[100] Training : loss: 1388.48 accuracy : 0.59375 Validation :  loss: 471.19 accuracy : 0.5625\n",
            "[125] Training : loss: 1388.48 accuracy : 0.59375 Validation :  loss: 471.06 accuracy : 0.5625\n",
            "[150] Training : loss: 1388.50 accuracy : 0.59375 Validation :  loss: 472.10 accuracy : 0.5659722222222222\n",
            "[175] Training : loss: 1388.48 accuracy : 0.59375 Validation :  loss: 471.43 accuracy : 0.5625\n",
            "[200] Training : loss: 1388.28 accuracy : 0.59375 Validation :  loss: 471.62 accuracy : 0.5659722222222222\n",
            "[225] Training : loss: 1388.28 accuracy : 0.59375 Validation :  loss: 471.39 accuracy : 0.5625\n",
            "[250] Training : loss: 1388.28 accuracy : 0.59375 Validation :  loss: 471.36 accuracy : 0.5659722222222222\n",
            "[275] Training : loss: 1388.28 accuracy : 0.59375 Validation :  loss: 471.43 accuracy : 0.5625\n",
            "[300] Training : loss: 1388.28 accuracy : 0.59375 Validation :  loss: 471.95 accuracy : 0.5659722222222222\n",
            "[325] Training : loss: 1388.28 accuracy : 0.59375 Validation :  loss: 472.14 accuracy : 0.5659722222222222\n",
            "[350] Training : loss: 1388.28 accuracy : 0.59375 Validation :  loss: 471.58 accuracy : 0.5659722222222222\n",
            "[375] Training : loss: 1388.28 accuracy : 0.59375 Validation :  loss: 471.68 accuracy : 0.5659722222222222\n",
            "[400] Training : loss: 1388.28 accuracy : 0.59375 Validation :  loss: 471.03 accuracy : 0.5659722222222222\n",
            "[425] Training : loss: 1388.28 accuracy : 0.59375 Validation :  loss: 471.04 accuracy : 0.5659722222222222\n",
            "[450] Training : loss: 1388.28 accuracy : 0.59375 Validation :  loss: 471.04 accuracy : 0.5659722222222222\n",
            "[475] Training : loss: 1388.28 accuracy : 0.59375 Validation :  loss: 471.03 accuracy : 0.5659722222222222\n",
            "[500] Training : loss: 1388.28 accuracy : 0.59375 Validation :  loss: 471.03 accuracy : 0.5659722222222222\n",
            "[525] Training : loss: 1388.28 accuracy : 0.59375 Validation :  loss: 471.03 accuracy : 0.5659722222222222\n",
            "[550] Training : loss: 1388.28 accuracy : 0.59375 Validation :  loss: 471.03 accuracy : 0.5659722222222222\n",
            "[575] Training : loss: 1388.28 accuracy : 0.59375 Validation :  loss: 471.02 accuracy : 0.5659722222222222\n",
            "[600] Training : loss: 1388.28 accuracy : 0.59375 Validation :  loss: 471.02 accuracy : 0.5659722222222222\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model =torch.load('/content/drive/MyDrive/PRML LABs/PRML Major Project/model_lda.pth')\n",
        "with torch.no_grad():\n",
        "    acc = 0.0\n",
        "    j = 0\n",
        "    for i, data in enumerate(test_lda):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device = device).float()\n",
        "        opt.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        _,pred = torch.max(outputs,0)\n",
        "        pred = pred.cpu().numpy()\n",
        "        labels = labels.numpy()\n",
        "        acc += np.sum(pred == labels)\n",
        "        j += 1\n",
        "print(f\"accuracy : {acc/j}\")"
      ],
      "metadata": {
        "id": "XZA2-HVuSchN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2e7222c-9a67-4112-c735-1cfaba8c2e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.6041666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-03d8390d25d3>:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = self.output_layer(x)\n"
          ]
        }
      ]
    }
  ]
}